# -*- coding: utf-8 -*-
# Arabic CX Dashboard (3 Dimensions) â€” Streamlit
# Files expected in the same folder:
#   - MUN.csv
#   - Digital_Data_tables2.xlsx
#
# Run:
#   streamlit run Arabic_Dashboard.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io, re
from datetime import datetime
from pathlib import Path

# =========================================================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© + Ø§ØªØ¬Ø§Ù‡ RTL
# =========================================================
st.set_page_config(page_title="Ù„ÙˆØ­Ø© ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ÙŠÙ† â€” Ù†Ø³Ø®Ø© Ø¹Ø±Ø¨ÙŠØ©", layout="wide")
PASTEL = px.colors.qualitative.Pastel

# Ø´Ø¹Ø§Ø± Ø£Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø©
LOGO_URL = "https://raw.githubusercontent.com/roum71/rakcx2025/main/assets/mini_header2.png"
st.markdown(f"""
    <div style="text-align:center; margin-top:-40px;">
        <img src="{LOGO_URL}" alt="Logo" style="width:950px; max-width:95%; height:auto;">
    </div>
    <hr style="margin-top:20px; margin-bottom:10px;">
""", unsafe_allow_html=True)

# Ø§ØªØ¬Ø§Ù‡ Ø¹Ø±Ø¨ÙŠ ÙˆØ®Ø· Ø¬Ù…ÙŠÙ„
st.markdown("""
    <style>
        html, body, [class*="css"] {direction:rtl; text-align:right; font-family:"Tajawal","Cairo","Segoe UI";}
        .stTabs [data-baseweb="tab-list"] {flex-direction: row-reverse;}
        .stDownloadButton, .stButton > button {font-weight:600;}
    </style>
""", unsafe_allow_html=True)

# =========================================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# =========================================================
@st.cache_data(show_spinner=False)
def load_data():
    df = pd.read_csv("MUN.csv", encoding="utf-8", low_memory=False)
    df.columns = [c.strip().upper() for c in df.columns]
    df.columns = [c.replace('DIM', 'Dim') for c in df.columns]

    lookup_catalog = {}
    xls_path = Path("Digital_Data_tables2.xlsx")
    if xls_path.exists():
        xls = pd.ExcelFile(xls_path)
        for sheet in xls.sheet_names:
            tbl = pd.read_excel(xls, sheet_name=sheet)
            tbl.columns = [str(c).strip().upper() for c in tbl.columns]
            lookup_catalog[sheet.strip().upper()] = tbl
    return df, lookup_catalog

def series_to_percent(vals: pd.Series):
    vals = pd.to_numeric(vals, errors="coerce").dropna()
    if len(vals) == 0:
        return np.nan
    mx = vals.max()
    if mx <= 5:
        return ((vals - 1) / 4 * 100).mean()
    elif mx <= 10:
        return ((vals - 1) / 9 * 100).mean()
    else:
        return vals.mean()

def detect_nps(df: pd.DataFrame):
    cand_cols = [c for c in df.columns if ("NPS" in c.upper()) or ("RECOMMEND" in c.upper())]
    if not cand_cols:
        return np.nan, 0, 0, 0, None
    col = cand_cols[0]
    s = pd.to_numeric(df[col], errors="coerce").dropna()
    if len(s) == 0:
        return np.nan, 0, 0, 0, col
    promoters = (s >= 9).sum()
    passives = ((s >= 7) & (s <= 8)).sum()
    detract = (s <= 6).sum()
    total = len(s)
    promoters_pct = promoters / total * 100
    detract_pct = detract / total * 100
    nps = promoters_pct - detract_pct
    return nps, promoters_pct, passives, detract, col

def autodetect_metric_cols(df: pd.DataFrame):
    csat = next((c for c in df.columns if "CSAT" in c.upper()), None)
    ces = next((c for c in df.columns if "FEES" in c.upper()), None)
    nps = next((c for c in df.columns if "NPS" in c.upper()), None)
    return csat, ces, nps

df, lookup_catalog = load_data()

# =========================================================
# Ø§Ù„ÙÙ„Ø§ØªØ±
# =========================================================
st.sidebar.header("ğŸ›ï¸ Ø§Ù„ÙÙ„Ø§ØªØ±")
df_filtered = df.copy()
common_keys = ["LANGUAGE", "SERVICE", "AGE", "PERIOD", "CHANNEL"]
candidate_filter_cols = [c for c in df.columns if any(k in c.upper() for k in common_keys)]

def apply_lookup(column_name: str, s: pd.Series) -> pd.Series:
    key = column_name.strip().upper()
    match_key = next((k for k in lookup_catalog.keys() if key in k or k in key), None)
    if not match_key: return s
    tbl = lookup_catalog[match_key].copy()
    tbl.columns = [str(c).strip().upper() for c in tbl.columns]
    if len(tbl.columns) < 2: return s
    map_dict = dict(zip(tbl.iloc[:,0].astype(str), tbl.iloc[:,1].astype(str)))
    return s.astype(str).map(map_dict).fillna(s)

df_filtered_display = df_filtered.copy()
for col in candidate_filter_cols:
    df_filtered_display[col] = apply_lookup(col, df_filtered[col])

with st.sidebar.expander("ØªØ·Ø¨ÙŠÙ‚/Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ„Ø§ØªØ±"):
    applied_filters = {}
    for col in candidate_filter_cols:
        df_filtered[col] = apply_lookup(col, df_filtered[col])
        options = sorted(df_filtered_display[col].dropna().unique().tolist())
        sel = st.multiselect(f"{col}", options, default=options)
        applied_filters[col] = sel
for col, selected in applied_filters.items():
    df_filtered = df_filtered[df_filtered[col].isin(selected)]
df_view = df_filtered.copy()

# =========================================================
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
# =========================================================
tab_data, tab_sample, tab_kpis, tab_dimensions, tab_services, tab_unsat, tab_pareto = st.tabs([
    "ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
    "ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©",
    "ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª",
    "ğŸ§© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯",
    "ğŸ“‹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
    "ğŸ’¬ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø¶Ø§ (Pareto)",
    "ğŸ’¬ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© (Pareto)"
])

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# =========================================================
with tab_data:
    st.subheader("ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©)")
    st.dataframe(df_view, use_container_width=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H%M")
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df_view.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)", data=buf.getvalue(),
                       file_name=f"Filtered_Data_{ts}.xlsx")

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©
# =========================================================
with tab_sample:
    st.subheader("ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©")
    total = len(df_view)
    st.markdown(f"### ğŸ§® Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯: {total:,}")
    chart_type = st.radio("ğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù…", ["Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©", "Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ"], index=0, horizontal=True)
    for col in candidate_filter_cols:
        counts = df_view[col].value_counts().reset_index()
        counts.columns = [col, "Count"]
        counts["Percentage"] = counts["Count"]/counts["Count"].sum()*100
        if chart_type == "Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©":
            fig = px.bar(counts, x=col, y="Count", text="Count", color=col,
                         color_discrete_sequence=PASTEL)
        else:
            fig = px.pie(counts, names=col, values="Count", hole=0.3)
        st.plotly_chart(fig, use_container_width=True)

# =========================================================
# ğŸ’¬ ØªØ¨ÙˆÙŠØ¨ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø¶Ø§ (Pareto)
# =========================================================
with tab_unsat:
    st.subheader("ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø¶Ø§ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© (Pareto)")

    unsat_col = next((c for c in df_view.columns if "MOST_UNSAT" in c.upper()), None)
    if not unsat_col:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙˆØ¯ Most_Unsat.")
    else:
        data_unsat = df_view[[unsat_col]].copy()
        data_unsat.columns = ["Comment"]
        data_unsat["Comment"] = data_unsat["Comment"].astype(str).str.strip()

        exclude_terms = ["", " ", "Ù„Ø§ ÙŠÙˆØ¬Ø¯", "Ù„Ø§ÙŠÙˆØ¬Ø¯", "Ù„Ø§Ø´ÙŠØ¡", "Ù„Ø§ Ø´ÙŠØ¡",
                         "none", "no", "nothing", "nil", "Ø¬ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "ok", "ØªÙ…Ø§Ù…", "great"]
        data_unsat = data_unsat[~data_unsat["Comment"].str.lower().isin([t.lower() for t in exclude_terms])]
        data_unsat = data_unsat[data_unsat["Comment"].apply(lambda x: len(x.split()) >= 2)]

        if data_unsat.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù†ØµÙŠØ© ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
        else:
            themes = {
                "Ø§Ù„Ø³Ø±Ø¹Ø© / Ø§Ù„Ø£Ø¯Ø§Ø¡": ["Ø¨Ø·Ø¡", "ØªØ£Ø®ÙŠØ±", "Ø§Ù†ØªØ¸Ø§Ø±", "delay", "slow", "Ø²Ù…Ù†", "ÙˆÙ‚Øª"],
                "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ / Ø§Ù„Ù…Ù†ØµØ©": ["ØªØ·Ø¨ÙŠÙ‚", "app", "Ù…Ù†ØµØ©", "system", "Ù…ÙˆÙ‚Ø¹", "Ø¨ÙˆØ§Ø¨Ø©", "ØµÙØ­Ø©"],
                "Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª / Ø§Ù„Ø®Ø·ÙˆØ§Øª": ["Ø¥Ø¬Ø±Ø§Ø¡", "Ø§Ø¬Ø±Ø§Ø¡", "Ø¹Ù…Ù„ÙŠØ©", "process", "Ø®Ø·ÙˆØ§Øª", "Ù…Ø±Ø§Ø­Ù„"],
                "Ø§Ù„Ø±Ø³ÙˆÙ… / Ø§Ù„Ø¯ÙØ¹": ["Ø±Ø³ÙˆÙ…", "Ø¯ÙØ¹", "fee", "ØªÙƒÙ„ÙØ©", "Ø³Ø¯Ø§Ø¯", "pay"],
                "Ø§Ù„ØªÙˆØ§ØµÙ„ / Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ": ["Ø±Ø¯", "ØªÙˆØ§ØµÙ„", "Ø§ØªØµØ§Ù„", "support", "response", "Ù…Ø³Ø§Ø¹Ø¯Ø©"],
                "Ø§Ù„ÙˆØ¶ÙˆØ­ / Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª": ["Ù…Ø¹Ù„ÙˆÙ…Ø©", "Ø¥ÙŠØ¶Ø§Ø­", "clarity", "instructions", "Ø¨ÙŠØ§Ù†Ø§Øª", "Ø´Ø±Ø­"],
                "Ø§Ù„Ø£Ù…Ø§Ù† / Ø§Ù„Ø¯Ø®ÙˆÙ„": ["ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±", "Ø¯Ø®ÙˆÙ„", "login", "ØªØ­Ù‚Ù‚", "Ø£Ù…Ø§Ù†"]
            }

            def classify_text(txt):
                t = txt.lower()
                for theme, keys in themes.items():
                    if any(k in t for k in keys):
                        return theme
                return "ØºÙŠØ± Ù…ØµÙ†Ù‘Ù"

            data_unsat["Ø§Ù„Ù…Ø­ÙˆØ±"] = data_unsat["Comment"].apply(classify_text)
            data_unsat = data_unsat[data_unsat["Ø§Ù„Ù…Ø­ÙˆØ±"] != "ØºÙŠØ± Ù…ØµÙ†Ù‘Ù"]

            summary = data_unsat.groupby("Ø§Ù„Ù…Ø­ÙˆØ±").agg({
                "Comment": lambda x: " / ".join(x.tolist())
            }).reset_index()
            summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"] = summary["Comment"].apply(lambda x: len(x.split("/")))
            summary = summary.sort_values("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", ascending=False).reset_index(drop=True)
            summary["Ø§Ù„Ù†Ø³Ø¨Ø© (%)"] = summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"]/summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"].sum()*100
            summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] = summary["Ø§Ù„Ù†Ø³Ø¨Ø© (%)"].cumsum()
            summary["Ø§Ù„Ù„ÙˆÙ†"] = np.where(summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] <= 80, "#E74C3C", "#BDC3C7")
            if not summary[summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] > 80].empty:
                first_above = summary[summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] > 80].index[0]
                summary.loc[first_above, "Ø§Ù„Ù„ÙˆÙ†"] = "#E74C3C"

            st.dataframe(summary[["Ø§Ù„Ù…Ø­ÙˆØ±","Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª","Ø§Ù„Ù†Ø³Ø¨Ø© (%)","Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)","Comment"]]
                         .rename(columns={"Comment":"Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª (Ù…Ø¬Ù…Ø¹Ø©)"}).style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© (%)":"{:.1f}%", "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)":"{:.1f}%"}),
                         use_container_width=True, hide_index=True)

            fig = go.Figure()
            fig.add_bar(x=summary["Ø§Ù„Ù…Ø­ÙˆØ±"], y=summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"], marker_color=summary["Ø§Ù„Ù„ÙˆÙ†"], name="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª")
            fig.add_scatter(x=summary["Ø§Ù„Ù…Ø­ÙˆØ±"], y=summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"], yaxis="y2",
                            name="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", mode="lines+markers+text",
                            text=[f"{v:.1f}%" for v in summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"]],
                            textposition="top center", line=dict(color="#2E86DE", width=3))
            fig.update_layout(
                title="ğŸ“Š ØªØ­Ù„ÙŠÙ„ Pareto Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø¶Ø§ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©",
                xaxis=dict(title="Ø§Ù„Ù…Ø­ÙˆØ±", tickangle=-15),
                yaxis=dict(title="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"),
                yaxis2=dict(title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", overlaying="y", side="right", range=[0,110]),
                height=600, bargap=0.3, legend=dict(orientation="h", y=-0.2)
            )
            st.plotly_chart(fig, use_container_width=True)

# =========================================================
# ØªØ­Ø³ÙŠÙ†Ø§Øª Ø´ÙƒÙ„ÙŠØ©
# =========================================================
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer, [data-testid="stFooter"] {opacity: 0.03 !important; height: 1px !important; overflow: hidden !important;}
    </style>
""", unsafe_allow_html=True)
